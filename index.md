# Ryan Herr

## Bio 1: for Fast.ai application

Data scientist in the insurance industry. 3 years experience doing data wrangling, exploratory data analysis, visualization, and machine learning in Python. 20+ years playing with code in a variety of languages.

I'd like to apply deep learning to generate music and visual art. For example, I'm teaching a computer to make music in bluegrass banjo style. So far, [I've tried probabilistic context-free grammars](https://twitter.com/rrherr/status/963235146399928320) and markov chains. Next I'd like to try recurrent neural networks and sequence-to-sequence models. 

I aspire to be a “Banjo Data Scientist”: Person who is better at playing banjo than any statistician or software engineer, and better at statistics & software engineering than any banjo player.

I completed fast.ai Deep Learning Part 1 as an International Fellowship participant, October-December 2017. I was accepted to Part 2, which is March-April 2018.

 
## Bio 2: for State Farm Data Science Center of Excellence

Over the past 8 years at State Farm, I worked in both technical & business roles, in several departments: SR, Systems, Innovation, EIS, and L&D. Along the way, I found a few niches:

#### Identify business pain points, and communicate solutions
For example, I’ve been a Hack Day winner the past four years, by applying lessons learned from infomercials – really! Behind all the schtick, infomercials define clear problems and demo how their product solves them. This applies to data science, too: I’m passionate about creating data products to solve business problems. 

This is hard! Data scientists work with math, but pain points are often expressed in stories, so we have to translate from qualitative to quantitative. This takes creativity and consulting skills. I first gained this experience on the Innovation Team, where I helped clients translate entrepreneurial ideas into testable hypotheses. I've continued in client­-facing roles with data science projects such as Third Party Auto Injury.

In addition to pitching and consulting, I also enjoy teaching. For example, I explained Hadoop with a unique demo, using Skittles to represent data. An executive complimented, “I learned more in the first 10 minutes of your presentation than I did in the all-­day Cloudera class.”

#### Take on less glamorous tasks, to enable predictive modeling projects
This includes wrangling dirty data, navigating State Farm process, and writing MapReduce code to process data in parallel. For example, I’ve used Hadoop for several Claims projects to reduce processing time from hours to minutes.

I strive to be a “force multiplier” for data science teams by doing whatever is needed. This has enabled some of our best modelers to spend more time focused on modeling. But although others in the CoE have more machine learning expertise, I’m competent and continuing to grow, thanks to help from online courses, Kaggle competitions, and my CoE teammates.

#### Develop data visualizations 
I have experience developing data visualizations and web applications using JavaScript frameworks such as D3 and React. For example, the Claims Early Notification Tool visualizes
new and unexpected claims trends to help leaders decide where to focus attention.

D3 is generally used to produce a final product, but for more exploratory works-­in-­progress, I use Seaborn in IPython Notebook. My interest in writing code to create visuals ties back to my interdisciplinary degree in Arts Technology from ISU. I’ve also studied visualization through Edward Tufte’s class and books.

**I’m interested in applying data science to optimize business operations and influence decision-making.** I would love to serve on a small persistent team embedded in a business area.


## Bio 3: from most recent performance review and resumes

#### Data Scientist, COUNTRY Financial

Serve in a “player-coach” role, doing data science projects and leading a team of 3 data scientists, at a Fortune 1000 insurance company.

Billing interim solution
- Billing didn't have a consistent way to determine the value of customers when making service decisions, especially exception requests. And the Billing System Conversion created urgency. They needed an interim solution before the Customer Lifetime Value model could be completed.
- In January, Billing began to pilot the interim solution I helped develop. The machine learning model was able to replicate supervisor decisions 89% of the time, which is close to the match rate of 92% that the supervisors had with each other.
- The pilot enabled us to quickly learn and iterate, and reduced time to make decision from 1:42 (supervisor review of factors) to 2 seconds (system generated).

Customer Lifetime Value
- The Billing, OE, and Analytics teams partnered to develop a Customer Lifetime Value model. 
- CLV uses machine learning to predict retention and calculate future policy value, for each policy in a household, across the customer's projected lifetime. These CLV scores enable customer segmentation for our most valuable households.
- CLV is in production for 9 billing use cases. Billing reps love how it enables them to make confident, consistent decisions quickly, with fewer escalations and less time spent researching exceptions.
- Spokane Agency said CLV is "remarkably accurate."

Auto Reunderwriting
- Helped develop Auto Reunderwriting model to replicate non-renewal decisions. Served as both manager and data scientist due to shortage of resources.
- Began pilot with Missouri in November. Underwriting validated that the model correctly identified 37 "no change" decisions, and only twice mis-identified "intent to non-renew" as "no change." The initial success is encouraging.
- This technology may enable us to do the same reunderwriting work with only 80% of the effort, freeing up capacity for other activities.
- Brian James said, "Ryan and his group have been outstanding to work with, truly partnering with our area to make us better. I have been very impressed."

Leadership Council presentation
- Designed and delivered executive education on Robotic Process Automation and Machine Learning for Leadership Council. Clarified concepts using simple diagrams and definitions. Documented recent uses in Customer Service / Billing, and future uses in Digital Customer Experience and Life New Business.
- Received feedback: "Well done! You presented yourself as the expert in the room, open and understanding of others’ questions, and everyone walked away with confidence in our teams for moving these capabilities forward."
- I also presented on Machine Learning at the ITS Hackathon, Analytics Huddle, and Champaign-Urbana Data Science User Group.

#### Data Scientist, State Farm

Developed machine learning models to improve decisions in Claims and Call Center operations.

As a leader:
- **Led project team** to deploy and support the Claims Early Notification Tool. This dashboard visualizes emerging trends to help leaders decide where to focus attention. Managed activities of 3 analysts, and relationship with business partner.
- **Hiring:** Evaluated 26 candidate work samples (a predictive modeling challenge) and chose who to interview. Led all technical interviews. Guided decision to hire 3 data scientists.
- **Talent development:** Mentored by State Farm’s top two data scientists. “Paid it forward” by teaching Python programming and machine learning to analysts from Actuary, IT, and Marketing.
- **Established new processes** to streamline data governance and implement predictive models in production. Demonstrated initiative and influence to negotiate buy-in with leaders across multiple functions.

As an individual contributor:
- Analyzed unstructured text data to categorize **auto injury claims** by type and complexity, and identify opportunities to improve cycle time.
- Forecasted call volume in the **Customer Care Center**, to optimize staffing and scheduling and meet service level goals.
- Automated processing to fix skewed satellite images from **catastrophe claims**, to estimate damages using a deep learning model.
- Tech skills: **Data visualization** with Python, D3.js, and Excel. **Analytics and statistical modeling** with Python (scikit-learn and pandas). **Big data** with Hadoop and Spark.

